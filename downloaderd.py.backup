import os
from datetime import datetime, timedelta
import time
import logging
import subprocess
from pathlib import Path

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(message)s',
    handlers=[
        logging.FileHandler('downloaderd.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

mount = True

def log(string):
    """Legacy logging function maintained for compatibility"""
    string = f'{datetime.utcnow()} {os.getpid()} {string}\n'
    with open('log.txt', 'a+') as f:
        f.write(string)

path = "/gefs/gefs/" if mount else "./gefs/"
whichpath = '/gefs/whichgefs' if mount else 'whichgefs'
statuspath = '/gefs/serverstatus' if mount else 'serverstatus'

def mostrecent():
    """Get most recent GEFS cycle time"""
    now = datetime.utcnow()
    return datetime(now.year, now.month, now.day, int(now.hour / 6) * 6) - timedelta(hours=6)

def currgefs():
    """Get current GEFS cycle from whichgefs file"""
    try:
        with open(whichpath) as f:
            s = f.readline().strip()
        if not s:
            return mostrecent() - timedelta(hours=6)
        now = datetime.strptime(s, "%Y%m%d%H")
        return datetime(now.year, now.month, now.day, int(now.hour / 6) * 6)
    except (FileNotFoundError, ValueError):
        return mostrecent() - timedelta(hours=6)

def run_downloader():
    """Run the downloader script and handle errors"""
    try:
        logger.info("Starting downloader")
        result = subprocess.run(['python3', 'downloader.py'], 
                              capture_output=True, 
                              text=True,
                              check=True)
        logger.info("Downloader completed successfully")
        logger.debug(f"Downloader output: {result.stdout}")
        return True
    except subprocess.CalledProcessError as e:
        logger.error(f"Downloader failed with code {e.returncode}")
        logger.error(f"Error output: {e.stderr}")
        return False
    except Exception as e:
        logger.error(f"Failed to run downloader: {str(e)}")
        return False

def check_data_validity(timestamp):
    """Check if data files exist for a given timestamp"""
    base_name = timestamp.strftime("%Y%m%d%H")
    # Check first forecast hour file exists
    first_file = Path(path) / f"{base_name}_{base_name}_01.npy"
    if not first_file.exists():
        return False
    
    # Check file 6 hours ahead exists
    forecast = timestamp + timedelta(hours=6)
    forecast_file = Path(path) / f"{base_name}_{forecast.strftime('%Y%m%d%H')}_01.npy"
    return forecast_file.exists()

def cleanup_old_data(curr_run, new_run):
    """Clean up old data files while maintaining required overlap"""
    try:
        if curr_run and new_run:
            # Keep files from last 384 hours (16 days)
            cutoff = new_run - timedelta(hours=384)
            for filename in os.listdir(path):
                if filename.endswith('.npy'):
                    file_time = datetime.strptime(filename.split('_')[0], "%Y%m%d%H")
                    if file_time < cutoff:
                        try:
                            os.remove(os.path.join(path, filename))
                            logger.info(f"Removed old file: {filename}")
                        except Exception as e:
                            logger.error(f"Failed to remove {filename}: {str(e)}")
    except Exception as e:
        logger.error(f"Error in cleanup: {str(e)}")

def update_status(message):
    """Update the status file"""
    try:
        with open(statuspath, "w") as f:
            f.write(message)
    except Exception as e:
        logger.error(f"Failed to update status: {str(e)}")

def main():
    """Main daemon loop"""
    # Ensure directories exist
    os.makedirs(path, exist_ok=True)
    
    update_status("Initializing. Please check again later.")
    
    while True:
        try:
            curr_run = currgefs()
            next_run = curr_run + timedelta(hours=6)
            logger.info(f"Current run: {curr_run}, Next run: {next_run}")
            
            # Run downloader
            if run_downloader():
                # Verify data was downloaded correctly
                if check_data_validity(next_run):
                    logger.info(f"Successfully downloaded data for {next_run}")
                    cleanup_old_data(curr_run, next_run)
                    update_status("Ready")
                else:
                    logger.error("Data validation failed")
                    update_status("Error: Data validation failed")
            else:
                logger.error("Downloader failed")
                update_status("Error: Download failed")
            
            # Wait before next check (5 minutes)
            time.sleep(300)
            
        except Exception as e:
            logger.error(f"Error in main loop: {str(e)}")
            update_status(f"Error: {str(e)}")
            time.sleep(300)  # Wait before retry

if __name__ == "__main__":
    main()
